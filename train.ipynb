{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97EG0TKvt0Cj"
   },
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HP6SLKszsfnd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import xgboost as xgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfYmxVNct8su"
   },
   "source": [
    "## Lectura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/caro6852lq/MachineLearning_PredictPricesProperties/raw/refs/heads/main/Data/Dataset_Inmuebles.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fd6eogZ49sdI"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(url, sheet_name=0)   # primera hoja\n",
    "df2 = pd.read_excel(url, sheet_name=1)   # segunda hoja\n",
    "df3 = pd.read_excel(url, sheet_name=2)   # tercera hoja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qFzmIcu-DQ-P"
   },
   "outputs": [],
   "source": [
    "df1df2 = df1.merge(df2, how = 'left', on='ID') # hago merge de las dos primeras hojas a través del ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bDQKAdkm42kx"
   },
   "outputs": [],
   "source": [
    "df = df1df2.merge(df3, how = 'left', on='ID') # agrego al merge la 3° hoja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGA29F9zGoMJ"
   },
   "source": [
    "## Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o2jeYYuiHzzl"
   },
   "outputs": [],
   "source": [
    "## Ajusto la columna de precio\n",
    "df[\"price_usd\"] = (\n",
    "    df[\"price_usd\"]\n",
    "      .str.replace(\"k\", \"\", regex=True)   # quita k/K finales\n",
    "      )\n",
    "df[\"price_usd\"] = df[\"price_usd\"].astype(\"float64\")\n",
    "df[\"price_usd\"] = df[\"price_usd\"]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-9pcbYzfJtie"
   },
   "outputs": [],
   "source": [
    "#Transformar Latitud a float64\n",
    "# Primero, debes reemplazar los puntos incorrectos. Usaremos regex para transformar el formato.\n",
    "df['lat'] = df['lat'].str.replace('.', '', regex=False)  # Eliminar todos los puntos\n",
    "df['lat'] = df['lat'].apply(lambda x: x[:3] + '.' + x[3:]) #sumo el punto dp de los tres primeros valores\n",
    "df['lat'] = df['lat'].astype('float64') # paso a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kq1gAt8gMu4N"
   },
   "outputs": [],
   "source": [
    "#Transformar lonitud a float64\n",
    "# Primero, debes reemplazar los puntos incorrectos. Usaremos regex para transformar el formato.\n",
    "df['lon'] = df['lon'].str.replace('.', '', regex=False)  # Eliminar todos los puntos\n",
    "df['lon'] = df['lon'].apply(lambda x: x[:3] + '.' + x[3:]) #sumo el punto dp de los tres primeros valores\n",
    "df['lon'] = df['lon'].astype('float64') # paso a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazo los nulos por \"sin dato\"\n",
    "df.fillna({'property_type': 'Sin Dato'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completar nulos\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1752925451258,
     "user": {
      "displayName": "Carolina Vergara",
      "userId": "17536471684236357967"
     },
     "user_tz": 180
    },
    "id": "w2fRYJN3w9Jx",
    "outputId": "b25d9e16-feaf-4c48-84a8-dbcd32739551"
   },
   "outputs": [],
   "source": [
    "#Filtro valores atípicos\n",
    "media = df[\"price_usd\"].mean()\n",
    "desv_std = df[\"price_usd\"].std()\n",
    "\n",
    "LI_DS = media - 3*desv_std\n",
    "LS_DS =  media + 3*desv_std\n",
    "\n",
    "df = df[(df[\"price_usd\"] >= LI_DS) & (df[\"price_usd\"] <= LS_DS)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1752925452748,
     "user": {
      "displayName": "Carolina Vergara",
      "userId": "17536471684236357967"
     },
     "user_tz": 180
    },
    "id": "bwicIKejowD-",
    "outputId": "7ae7a38e-84bc-44a9-d9bb-a89d47ddc9dd"
   },
   "outputs": [],
   "source": [
    "## Superficie Total por DS\n",
    "\n",
    "media = df[\"surface_total\"].mean()\n",
    "desv_std = df[\"surface_total\"].std()\n",
    "\n",
    "LI_DS = media - 3*desv_std\n",
    "LS_DS =  media + 3*desv_std\n",
    "\n",
    "df = df[(df[\"surface_total\"] >= LI_DS) & (df[\"surface_total\"] <= LS_DS)]\n",
    "df = df[(df[\"surface_total\"] >= 10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1752925454176,
     "user": {
      "displayName": "Carolina Vergara",
      "userId": "17536471684236357967"
     },
     "user_tz": 180
    },
    "id": "TOTXdAsAM0FU",
    "outputId": "6fb1b011-f0c2-44d8-e936-b7a24dd33858"
   },
   "outputs": [],
   "source": [
    "## En este caso tomo un modo arbitrario\n",
    "# Filtramos los valores dentro del rango para la superficie total\n",
    "df = df[(df[\"rooms\"] < 17) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1752925454196,
     "user": {
      "displayName": "Carolina Vergara",
      "userId": "17536471684236357967"
     },
     "user_tz": 180
    },
    "id": "zAUBIsYPc-sV",
    "outputId": "0b558370-b2d6-4b79-f565-efa2b02800c8"
   },
   "outputs": [],
   "source": [
    "## Borro los registros \"Sin Dato\" para tipo de propiedad\n",
    "df = df[df[\"property_type\"] !='Sin Dato']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eU5FSUwjxlp4"
   },
   "outputs": [],
   "source": [
    "## Saco: description, title, floor (x cantidad de nulos), columnas calculadas, expensas porque la mayoría tiene valor $0\n",
    "df=df[[\"property_type\",'lat', 'lon','price_usd', 'surface_total', 'surface_covered','rooms',\n",
    "       'barrio', 'comuna']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divido el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train = df_full_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full_train = df_full_train.price_usd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_full_train['price_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train):\n",
    "    dicts_full_train = df_full_train.to_dict(orient='records')\n",
    " \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_full_train = dv.fit_transform(dicts_full_train)\n",
    "\n",
    "    feature_names = list(dv.get_feature_names_out())\n",
    "\n",
    "    dfulltrain = xgb.DMatrix(X_full_train, label=y_full_train,\n",
    "                        feature_names=feature_names)\n",
    "\n",
    "    xgb_params = {\n",
    "        'eta': 0.3, \n",
    "        'max_depth': 5, \n",
    "        'min_child_weight': 1, \n",
    "         \n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "     \n",
    "        'nthread': 8,\n",
    "        'seed': 1,\n",
    "        'verbosity': 1,\n",
    "    }\n",
    "     \n",
    "    model = xgb.train(xgb_params,dfulltrain, num_boost_round=100)\n",
    " \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv, model = train(df_full_train, y_full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"model_xgb.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close()>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_out = open(output_file, 'wb')\n",
    "pickle.dump((dv,model),f_out)\n",
    "f_out.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (output_file, 'wb') as f_out:\n",
    "    pickle.dump((dv,model),f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.850970099170846"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = df_test.price_usd.values\n",
    "\n",
    "dicts_full_train = df_full_train.to_dict(orient='records')\n",
    " \n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_full_train = dv.fit_transform(dicts_full_train)\n",
    "\n",
    "dicts_test = df_test.to_dict(orient='records')\n",
    "X_test = dv.transform(dicts_test)\n",
    "\n",
    "feature_names = list(dv.get_feature_names_out())\n",
    "\n",
    "dfulltrain = xgb.DMatrix(X_full_train, label=y_full_train,\n",
    "                        feature_names=feature_names)\n",
    "\n",
    "\n",
    "dtest = xgb.DMatrix(X_test, feature_names=feature_names)\n",
    "\n",
    "y_test = df_test.price_usd.values\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "#Mido el modelo\n",
    "r2_score(y_test, y_pred)\n",
    "\n",
    "# RL r2_score --  0.7557617985788082\n",
    "# DT r2_score -- 0.7735939283232441\n",
    "# DT Ajustado r2_score -- 0.825\n",
    "# RF r2_score -- 0.8497901763819492\n",
    "# RF Ajustado r2_score -- 0.8627054610020553\n",
    "# XGB r2_score --- 0.8505679046774839\n",
    "# XGB Ajustado r2_score --- 0.8711028223293713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = {\n",
    "    'property_type': 'apartment',\n",
    "     'lat': -34.5438853785,\n",
    "     'lon': -58.4779876511999,\n",
    "     'surface_total': 40,\n",
    "     'surface_covered': 35,\n",
    "     'rooms': 4,\n",
    "     'barrio': 'SAAVEDRA',\n",
    "     'comuna': 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dv.transform([house])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = xgb.DMatrix(X, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_price = model.predict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12146.193], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggested_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "\n",
    "with open(\"train.ipynb\") as f:\n",
    "    notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "py_exporter = PythonExporter()\n",
    "py_code, _ = py_exporter.from_notebook_node(notebook)\n",
    "\n",
    "with open(\"train2.py\", \"w\") as f:\n",
    "    f.write(py_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPyCywVG5SUD2651c46SVd",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
